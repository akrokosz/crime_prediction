{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:46:49.153008400Z",
     "start_time": "2024-01-23T13:46:49.081966600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state', 'county', 'community', 'communityname', 'fold', 'population', 'householdsize', 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap', 'indianPerCap', 'AsianPerCap', 'OtherPerCap', 'HispPerCap', 'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ', 'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85', 'PctSameCity85', 'PctSameState85', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'LandArea', 'PopDens', 'PctUsePubTrans', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'LemasPctOfficDrugUn', 'PolicBudgPerPop', 'ViolentCrimesPerPop']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path1 = 'Datasets/communities.data'\n",
    "path2 = 'Datasets/communities.names'\n",
    "headers = []\n",
    "with open(path2, 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('@attribute'):\n",
    "            name = line.split()[1]\n",
    "            headers.append(name)\n",
    "print(headers)\n",
    "data = pd.read_csv(path1, sep=',', names=headers)\n",
    "data.drop('state', axis=1, inplace=True)\n",
    "data.drop('county', axis=1, inplace=True)\n",
    "data.drop('community', axis=1, inplace=True)\n",
    "data.drop('communityname', axis=1, inplace=True)\n",
    "data.drop('fold', axis=1, inplace=True)\n",
    "data.replace('?', np.NAN, inplace=True)\n",
    "na_percentage = data.isna().mean()\n",
    "high_na_columns = na_percentage[na_percentage > 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from copy import copy\n",
    "import time\n",
    "\n",
    "data_mice = copy(data)\n",
    "imputer = IterativeImputer(max_iter=300, random_state=42, tol=0.001, min_value=0, max_value=1)\n",
    "time_start = time.time()\n",
    "imputed_values = imputer.fit_transform(data_mice)\n",
    "time_stop = time.time()\n",
    "print(f\"Exec time: {time_stop-time_start}\")\n",
    "imputed_values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-23T13:46:50.142253100Z"
    }
   },
   "id": "8ac353fb6ec4fd90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_mice = pd.DataFrame(imputed_values)\n",
    "data_mice.columns = [col for col in headers if col not in ['state', 'county', 'community', 'communityname', 'fold', ]]\n",
    "data_mice"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3f88747e5543149a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mice_X = data_mice.iloc[:,:-1]\n",
    "mice_y = data_mice.iloc[:,-1]\n",
    "mice_X"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1597b2d9c2cb4c9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# \n",
    "# pca = PCA(n_components=60)\n",
    "# pca_mice_X = pca.fit_transform(mice_X)\n",
    "# pca_mice_X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd4520847b92adab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# \n",
    "# estimator = LinearRegression()\n",
    "# selector = RFE(estimator, n_features_to_select=60, step=0.1)\n",
    "# selector = selector.fit(mice_X, mice_y)\n",
    "# selected_features_mask = selector.support_\n",
    "# selected_feature_names = [column_name for (column_name, selected) in zip(mice_X.columns, selected_features_mask) if selected]\n",
    "# rfe_mice_X = mice_X[selected_feature_names]\n",
    "# rfe_mice_X = pd.DataFrame(rfe_mice_X, columns=selected_feature_names)\n",
    "# \n",
    "# rfe_mice_X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cc1b8e1e8ae4017"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(mice_X, mice_y, test_size=0.25, random_state=42)\n",
    "\n",
    "lasso = Lasso(alpha=0.0001)\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lasso.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"R^2: {r2}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bf753da2a370856"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(mice_X, mice_y, test_size=0.25, random_state=42)\n",
    "\n",
    "ridge = Ridge(alpha=0.0001, solver='cholesky')\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"R^2: {r2}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dcd77a603a821ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mice_X, mice_y, test_size=0.25, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'dart',\n",
    "    'num_leaves': 18,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 6,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "num_round = 10000\n",
    "bst = lgb.train(params, train_data, num_round)\n",
    "\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95000b8aa130c4ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X = mice_X\n",
    "y = mice_y\n",
    "\n",
    "estimators_params = {\n",
    "    SVR: {\n",
    "        'C': hp.loguniform('C', -3, 3),\n",
    "        'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly', 'sigmoid']),\n",
    "    }\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "best_estimators = {}\n",
    "for estimator, space in estimators_params.items():\n",
    "    print(f\"Optimizing {estimator.__name__}\")\n",
    "\n",
    "    def objective(params):\n",
    "        model = estimator(**params)\n",
    "        scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "        mse = -scores.mean()\n",
    "        print(f\"MSE: {mse}\")\n",
    "        r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "        r2 = r2_scores.mean()\n",
    "        print(f\"R2: {r2}\")\n",
    "        print(\"----------------------------------\")\n",
    "        return mse\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=200,\n",
    "                verbose=True)\n",
    "\n",
    "    best_params = space_eval(space, best)\n",
    "    print(f\"Best parameters for {estimator.__name__}: {best_params}\")\n",
    "\n",
    "    model = estimator(**best_params)\n",
    "    model.fit(X, y)\n",
    "    best_estimators[estimator] = model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20b040d29709cfb8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NEURAL NETWORK WITH L-BFGS SOLVER\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea4b9009e2a768c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_mice, X_val_mice, y_train_mice, y_val_mice = train_test_split(mice_X.astype(np.float32), mice_y.astype(np.float32), test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78b196e039225ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = y_train_mice.to_numpy()\n",
    "if y_train.ndim == 1:\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "y_val = y_val_mice.to_numpy()\n",
    "if y_val.ndim == 1:\n",
    "    y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "X_train = X_train_mice.to_numpy()\n",
    "X_val = X_val_mice.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f9e8d9965fcfd9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_probability\n",
      "  Downloading tensorflow_probability-0.21.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (1.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (1.24.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (3.0.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (0.4.0)\n",
      "Collecting dm-tree (from tensorflow_probability)\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-win_amd64.whl (101 kB)\n",
      "     ---------------------------------------- 0.0/101.4 kB ? eta -:--:--\n",
      "     ----------- ------------------------- 30.7/101.4 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 101.4/101.4 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<4.6.0 (from tensorflow_probability)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading tensorflow_probability-0.21.0-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/6.9 MB 10.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.6/6.9 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.2/6.9 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 36.9 MB/s eta 0:00:00\n",
      "Installing collected packages: dm-tree, typing-extensions, tensorflow_probability\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "Successfully installed dm-tree-0.1.8 tensorflow_probability-0.21.0 typing-extensions-4.5.0\n",
      "Requirement already satisfied: tensorflow_probability in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (1.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (1.24.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (3.0.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (0.4.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (0.1.8)\n",
      "Requirement already satisfied: typing-extensions<4.6.0 in c:\\users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages (from tensorflow_probability) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_probability"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:46:26.993002400Z",
     "start_time": "2024-01-23T13:46:24.624967600Z"
    }
   },
   "id": "5cb207a416d84fa9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valky\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfp\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper_func\u001B[39m(model, loss, train_x, train_y, val_x, val_y):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\__init__.py:41\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_six\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\__init__.py:45\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m INFINITE \u001B[38;5;28;01mas\u001B[39;00m INFINITE_CARDINALITY\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 96\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m service\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatching\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dense_to_ragged_batch\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatching\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dense_to_sparse_batch\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m division\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_service_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mservice\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserver_lib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DispatchServer\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mservice\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserver_lib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m WorkerServer\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compression_ops\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute_options\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoShardPolicy\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute_options\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExternalStatePolicy\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m division\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m structure\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gen_experimental_dataset_ops \u001B[38;5;28;01mas\u001B[39;00m ged_ops\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompress\u001B[39m(element):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwrapt\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nest\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m composite_tensor\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:41\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_six\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _pywrap_utils\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sparse_tensor \u001B[38;5;28;01mas\u001B[39;00m _sparse_tensor\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collections_abc \u001B[38;5;28;01mas\u001B[39;00m _collections_abc\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sorted\u001B[39m(dict_):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m composite_tensor\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constant_op\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types_pb2\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m execute\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m op_callbacks\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tfe\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_shape\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513\u001B[0m\n\u001B[0;32m    482\u001B[0m     _NP_TO_TF[pdt] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\n\u001B[0;32m    483\u001B[0m         _NP_TO_TF[dt] \u001B[38;5;28;01mfor\u001B[39;00m dt \u001B[38;5;129;01min\u001B[39;00m _NP_TO_TF \u001B[38;5;28;01mif\u001B[39;00m dt \u001B[38;5;241m==\u001B[39m pdt()\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    486\u001B[0m TF_VALUE_DTYPES \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(_NP_TO_TF\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m    489\u001B[0m _TF_TO_NP \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    490\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_HALF:\n\u001B[0;32m    491\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat16,\n\u001B[0;32m    492\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_FLOAT:\n\u001B[0;32m    493\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat32,\n\u001B[0;32m    494\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_DOUBLE:\n\u001B[0;32m    495\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat64,\n\u001B[0;32m    496\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT32:\n\u001B[0;32m    497\u001B[0m         np\u001B[38;5;241m.\u001B[39mint32,\n\u001B[0;32m    498\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT8:\n\u001B[0;32m    499\u001B[0m         np\u001B[38;5;241m.\u001B[39muint8,\n\u001B[0;32m    500\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT16:\n\u001B[0;32m    501\u001B[0m         np\u001B[38;5;241m.\u001B[39muint16,\n\u001B[0;32m    502\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT32:\n\u001B[0;32m    503\u001B[0m         np\u001B[38;5;241m.\u001B[39muint32,\n\u001B[0;32m    504\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT64:\n\u001B[0;32m    505\u001B[0m         np\u001B[38;5;241m.\u001B[39muint64,\n\u001B[0;32m    506\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT16:\n\u001B[0;32m    507\u001B[0m         np\u001B[38;5;241m.\u001B[39mint16,\n\u001B[0;32m    508\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT8:\n\u001B[0;32m    509\u001B[0m         np\u001B[38;5;241m.\u001B[39mint8,\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;66;03m# NOTE(touts): For strings we use np.object as it supports variable length\u001B[39;00m\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;66;03m# strings.\u001B[39;00m\n\u001B[0;32m    512\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_STRING:\n\u001B[1;32m--> 513\u001B[0m         \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobject\u001B[49m,\n\u001B[0;32m    514\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX64:\n\u001B[0;32m    515\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex64,\n\u001B[0;32m    516\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX128:\n\u001B[0;32m    517\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex128,\n\u001B[0;32m    518\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT64:\n\u001B[0;32m    519\u001B[0m         np\u001B[38;5;241m.\u001B[39mint64,\n\u001B[0;32m    520\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BOOL:\n\u001B[0;32m    521\u001B[0m         np\u001B[38;5;241m.\u001B[39mbool,\n\u001B[0;32m    522\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT8:\n\u001B[0;32m    523\u001B[0m         _np_qint8,\n\u001B[0;32m    524\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT8:\n\u001B[0;32m    525\u001B[0m         _np_quint8,\n\u001B[0;32m    526\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT16:\n\u001B[0;32m    527\u001B[0m         _np_qint16,\n\u001B[0;32m    528\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT16:\n\u001B[0;32m    529\u001B[0m         _np_quint16,\n\u001B[0;32m    530\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT32:\n\u001B[0;32m    531\u001B[0m         _np_qint32,\n\u001B[0;32m    532\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BFLOAT16:\n\u001B[0;32m    533\u001B[0m         _np_bfloat16,\n\u001B[0;32m    534\u001B[0m \n\u001B[0;32m    535\u001B[0m     \u001B[38;5;66;03m# Ref types\u001B[39;00m\n\u001B[0;32m    536\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_HALF_REF:\n\u001B[0;32m    537\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat16,\n\u001B[0;32m    538\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_FLOAT_REF:\n\u001B[0;32m    539\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat32,\n\u001B[0;32m    540\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_DOUBLE_REF:\n\u001B[0;32m    541\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat64,\n\u001B[0;32m    542\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT32_REF:\n\u001B[0;32m    543\u001B[0m         np\u001B[38;5;241m.\u001B[39mint32,\n\u001B[0;32m    544\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT32_REF:\n\u001B[0;32m    545\u001B[0m         np\u001B[38;5;241m.\u001B[39muint32,\n\u001B[0;32m    546\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT8_REF:\n\u001B[0;32m    547\u001B[0m         np\u001B[38;5;241m.\u001B[39muint8,\n\u001B[0;32m    548\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT16_REF:\n\u001B[0;32m    549\u001B[0m         np\u001B[38;5;241m.\u001B[39muint16,\n\u001B[0;32m    550\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT16_REF:\n\u001B[0;32m    551\u001B[0m         np\u001B[38;5;241m.\u001B[39mint16,\n\u001B[0;32m    552\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT8_REF:\n\u001B[0;32m    553\u001B[0m         np\u001B[38;5;241m.\u001B[39mint8,\n\u001B[0;32m    554\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_STRING_REF:\n\u001B[0;32m    555\u001B[0m         np\u001B[38;5;241m.\u001B[39mobject,\n\u001B[0;32m    556\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX64_REF:\n\u001B[0;32m    557\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex64,\n\u001B[0;32m    558\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX128_REF:\n\u001B[0;32m    559\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex128,\n\u001B[0;32m    560\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT64_REF:\n\u001B[0;32m    561\u001B[0m         np\u001B[38;5;241m.\u001B[39mint64,\n\u001B[0;32m    562\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT64_REF:\n\u001B[0;32m    563\u001B[0m         np\u001B[38;5;241m.\u001B[39muint64,\n\u001B[0;32m    564\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BOOL_REF:\n\u001B[0;32m    565\u001B[0m         np\u001B[38;5;241m.\u001B[39mbool,\n\u001B[0;32m    566\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT8_REF:\n\u001B[0;32m    567\u001B[0m         _np_qint8,\n\u001B[0;32m    568\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT8_REF:\n\u001B[0;32m    569\u001B[0m         _np_quint8,\n\u001B[0;32m    570\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT16_REF:\n\u001B[0;32m    571\u001B[0m         _np_qint16,\n\u001B[0;32m    572\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT16_REF:\n\u001B[0;32m    573\u001B[0m         _np_quint16,\n\u001B[0;32m    574\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT32_REF:\n\u001B[0;32m    575\u001B[0m         _np_qint32,\n\u001B[0;32m    576\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BFLOAT16_REF:\n\u001B[0;32m    577\u001B[0m         _np_bfloat16,\n\u001B[0;32m    578\u001B[0m }\n\u001B[0;32m    580\u001B[0m _QUANTIZED_DTYPES_NO_REF \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfrozenset\u001B[39m([qint8, quint8, qint16, quint16, qint32])\n\u001B[0;32m    581\u001B[0m _QUANTIZED_DTYPES_REF \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfrozenset\u001B[39m(\n\u001B[0;32m    582\u001B[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\crime_prediction\\lib\\site-packages\\numpy\\__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "def wrapper_func(model, loss, train_x, train_y, val_x, val_y):\n",
    "    shapes = [var.shape for var in model.trainable_variables]\n",
    "    n_tensors = len(shapes)\n",
    "\n",
    "    count = 0\n",
    "    idx = []  # stitch indices\n",
    "    part = []  # partition indices\n",
    "\n",
    "    for i, shape in enumerate(shapes):\n",
    "        n = np.product(shape)\n",
    "        idx.append(tf.reshape(tf.range(count, count + n, dtype=tf.int32), shape))\n",
    "        part.extend([i] * n)\n",
    "        count += n\n",
    "\n",
    "    part = tf.constant(part)\n",
    "\n",
    "    def assign_new_model_parameters(params_1d):\n",
    "        params = tf.dynamic_partition(params_1d, part, n_tensors)\n",
    "        for i, (shape, param) in enumerate(zip(shapes, params)):\n",
    "            model.trainable_variables[i].assign(tf.reshape(param, shape))\n",
    "\n",
    "    @tf.function\n",
    "    def f(params_1d):\n",
    "        with tf.GradientTape() as tape:\n",
    "            assign_new_model_parameters(params_1d)\n",
    "            loss_value = loss(model(train_x, training=True), train_y)\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        grads = tf.dynamic_stitch(idx, grads)\n",
    "\n",
    "        f.iter.assign_add(1)\n",
    "        tf.print(\"Iter:\", f.iter, \"loss:\", loss_value)\n",
    "\n",
    "        tf.py_function(f.history.append, inp=[loss_value], Tout=[])\n",
    "\n",
    "        model_output = model(val_x, training=False)\n",
    "        val_loss = loss(model_output, val_y)\n",
    "\n",
    "        return val_loss, grads\n",
    "\n",
    "    f.iter = tf.Variable(0)\n",
    "    f.history = []\n",
    "\n",
    "    f.idx = idx\n",
    "    f.assign_new_model_parameters = assign_new_model_parameters\n",
    "\n",
    "    return f\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T13:46:40.765023300Z",
     "start_time": "2024-01-23T13:46:39.185512600Z"
    }
   },
   "id": "fd2a1e6eba1300a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def create_model():\n",
    "    alpha_value = 0.2126152046916911\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=[mice_X.shape[1]]),\n",
    "\n",
    "        tf.keras.layers.Dense(60, activation=\"tanh\", kernel_regularizer=l2(alpha_value)),\n",
    "\n",
    "        tf.keras.layers.Dense(60, activation=\"tanh\", kernel_regularizer=l2(alpha_value)),\n",
    "\n",
    "        tf.keras.layers.Dense(30, activation=\"tanh\", kernel_regularizer=l2(alpha_value)),\n",
    "\n",
    "        tf.keras.layers.Dense(15, activation=\"tanh\", kernel_regularizer=l2(alpha_value)),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation=None)\n",
    "    ])\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c6945d0dba08ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, func, init_params, max_iterations=500, tolerance=9.011410429103892e-055, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    best_params = None\n",
    "    no_improve_count = 0\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        results = tfp.optimizer.lbfgs_minimize(\n",
    "            value_and_gradients_function=func,\n",
    "            initial_position=init_params,\n",
    "            tolerance=tolerance\n",
    "        )\n",
    "\n",
    "        # Update the model parameters\n",
    "        func.assign_new_model_parameters(results.position)\n",
    "\n",
    "        # Unpack only two values here: val_loss and _\n",
    "        val_loss, _ = func(results.position)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = results.position\n",
    "            no_improve_count = 0\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "\n",
    "        if no_improve_count >= patience:\n",
    "            print(f\"Stopping early at iteration {iteration}\")\n",
    "            break\n",
    "\n",
    "        # Update init_params for the next iteration\n",
    "        init_params = results.position\n",
    "\n",
    "    if best_params is not None:\n",
    "        func.assign_new_model_parameters(best_params)\n",
    "\n",
    "    return best_val_loss\n",
    "#nya\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bcbf76316f09cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pred_model = create_model()\n",
    "\n",
    "loss_fun = tf.keras.losses.MeanSquaredError()\n",
    "func = wrapper_func(pred_model, loss_fun, X_train, y_train, X_val, y_val)\n",
    "\n",
    "init_params = tf.dynamic_stitch(func.idx, pred_model.trainable_variables)\n",
    "\n",
    "best_val_loss = train_model(pred_model, func, init_params, max_iterations=800, tolerance=1e-5, patience=10)\n",
    "\n",
    "pred_outs = pred_model.predict(X_val)\n",
    "\n",
    "r2_val_score = r2_score(y_val, pred_outs)\n",
    "\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss}\")\n",
    "print(f\"R^2: {r2_val_score}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34dd082d931f8f8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import load, dump\n",
    "dump(load(\"best_tensor_combo_temp.joblib\"), \"best_tensor_combo_temp_014082.joblib\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da27d27873b3e1e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP REGRESSOR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d42fcb8cbcc66f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "estimators_params = {}\n",
    "\n",
    "\n",
    "estimators_params[MLPRegressor] ={\n",
    "    #[58, 45, 36, 61]\n",
    "    'layer_number': hp.choice('layer_number', range(4,5)),\n",
    "    'nn1' : hp.choice(\"nn1\", range(53,63,1)),\n",
    "    'nn2' : hp.choice(\"nn2\", range(40,50,1)),\n",
    "    'nn3' : hp.choice(\"nn3\", range(31,41,1)),\n",
    "    'nn4' : hp.choice(\"nn4\", range(56,67,1)),\n",
    "    # 'nn5' : hp.choice(\"nn5\", range(20,40,1)),\n",
    "    'activation': hp.choice('activation', ['relu', 'tanh']),  # Utrzymanie najlepszego wyboru\n",
    "    'solver': 'lbfgs',  # Utrzymanie najlepszego wyboru\n",
    "    'alpha': hp.uniform('alpha', 0.17, 0.22),  # Zwężony zakres wokół 0.1959\n",
    "    'max_iter': hp.choice('max_iter', range(1200, 1300, 10)),  # Zwężony zakres\n",
    "    'tol': hp.uniform('tol', 1e-6, 1e-3),\n",
    "    'shuffle': hp.choice('shuffle', [True, False]),  # Utrzymanie najlepszego wyboru\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.25,  # Utrzymanie najlepszego wyboru,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    best_combo\n",
    "except NameError:\n",
    "    best_combo = None\n",
    "\n",
    "best_estimators = {}\n",
    "for estimator, space in estimators_params.items():\n",
    "    print(estimator)\n",
    "\n",
    "    def objective(params: dict):\n",
    "\n",
    "        global best_combo\n",
    "\n",
    "        params[\"hidden_layer_sizes\"] = [params.pop(\"nn\"+str(i)) for i in range(1,params.pop(\"layer_number\")+1)]\n",
    "        for i in range(6):\n",
    "            if \"nn\"+str(i) in params.keys():\n",
    "                params.pop(\"nn\"+str(i))\n",
    "        # print(params)\n",
    "        model = estimator(**params)\n",
    "        model.fit(X_train_mice, y_train_mice)\n",
    "        y_pred_fillna = model.predict(X_val_mice)\n",
    "        mse = mean_squared_error(y_val_mice, y_pred_fillna)\n",
    "        print(f\"MSE: {mse}\")\n",
    "        mae = mean_absolute_error(y_val_mice, y_pred_fillna)\n",
    "        print(f\"MAE:  {mae}\")\n",
    "        r2 = r2_score(y_val_mice, y_pred_fillna)\n",
    "        print(f\"R2:  {r2}\")\n",
    "        if best_combo is None:\n",
    "            best_combo = {\n",
    "                \"model\": model,\n",
    "                \"mse\" : mse,\n",
    "                \"mae\" : mae,\n",
    "                \"r2\" : r2,\n",
    "                \"y_pred\": y_pred_fillna,\n",
    "            }\n",
    "        else:\n",
    "            if best_combo[\"mse\"] > mse:\n",
    "                best_combo = {\n",
    "                    \"model\": model,\n",
    "                    \"mse\" : mse,\n",
    "                    \"mae\" : mae,\n",
    "                    \"r2\" : r2,\n",
    "                    \"y_pred\": y_pred_fillna,\n",
    "                }\n",
    "                print(\"NEW_BEST_COMBO!\")\n",
    "                print(f\"MSE: {mse}\")\n",
    "                print(f\"MAE: {mae}\")\n",
    "                print(f\"R2: {r2}\")\n",
    "                dump(best_combo, 'best_combo_temp2.joblib')\n",
    "        return mse\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10000,\n",
    "                verbose=True)\n",
    "\n",
    "    print(\"BEST:\")\n",
    "    best_params = space_eval(space, best)\n",
    "    best_estimator = estimator(**best_params)\n",
    "    best_estimator.fit(X_train_mice, y_train_mice)\n",
    "    y_pred_est = best_estimator.predict(X_val_mice)\n",
    "    mae_est = mean_absolute_error(y_val_mice, y_pred_est)\n",
    "    mse_est = mean_squared_error(y_val_mice, y_pred_est)\n",
    "    r2_est = r2_score(y_val_mice, y_pred_est)\n",
    "    print(f\"MAE: {mae_est}\")\n",
    "    print(f\"MSE: {mse_est}\")\n",
    "    print(f\"R2: {r2_est}\")\n",
    "    print(\"BEST:\",best_params)\n",
    "    best_estimators[mse_est] = (best_estimator, best_params)\n",
    "\n",
    "best_mse = min(best_estimators.keys())\n",
    "best_regressor= (best_estimators[best_mse],  best_mse)\n",
    "print(best_combo)\n",
    "dump(best_combo, 'best_combo_new3.joblib')\n",
    "print(best_regressor)\n",
    "dump(best_regressor, 'best_regressor_new3.joblib')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eb5eefb4df805b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_combo[\"model\"].get_params())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deacb040d8e9f109"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def measure(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y, preds),\n",
    "        \"MSE\": mean_squared_error(y, preds),\n",
    "        \"R2\": r2_score(y, preds),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64da013ab82ba17e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "print(load(\"best_combo_temp_005400.joblib\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe961d2d263dea3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "measure(load(\"best_combo_temp_005400.joblib\")[\"model\"], X_val_mice, y_val_mice)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786b856ed4771a41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
