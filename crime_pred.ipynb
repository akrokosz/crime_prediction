{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state', 'county', 'community', 'communityname', 'fold', 'population', 'householdsize', 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap', 'indianPerCap', 'AsianPerCap', 'OtherPerCap', 'HispPerCap', 'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ', 'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85', 'PctSameCity85', 'PctSameState85', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'LandArea', 'PopDens', 'PctUsePubTrans', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'LemasPctOfficDrugUn', 'PolicBudgPerPop', 'ViolentCrimesPerPop']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    headers\n",
    "except NameError:\n",
    "    headers = []\n",
    "\n",
    "def import_raw_data() -> pd.DataFrame:\n",
    "    global headers\n",
    "    path1 = 'Datasets/communities.data'\n",
    "    path2 = 'Datasets/communities.names'\n",
    "    headers = []\n",
    "    with open(path2, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('@attribute'):\n",
    "                name = line.split()[1]\n",
    "                headers.append(name)\n",
    "    data = pd.read_csv(path1, sep=',', names=headers)\n",
    "    data.drop('state', axis=1, inplace=True)\n",
    "    data.drop('county', axis=1, inplace=True)\n",
    "    data.drop('community', axis=1, inplace=True)\n",
    "    data.drop('communityname', axis=1, inplace=True)\n",
    "    data.drop('fold', axis=1, inplace=True)\n",
    "    data.replace('?', np.NAN, inplace=True)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = import_raw_data()\n",
    "data.to_csv(\"data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a4e3071bd4ee49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA IMPUTED BY MICE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4c024f2ba2ea812"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "data_mice = copy(data)\n",
    "mice_X = data_mice.iloc[:,:-1]\n",
    "mice_y = data_mice.iloc[:,-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786b856ed4771a41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import time\n",
    "\n",
    "imputer = IterativeImputer(max_iter=500, random_state=42, tol=0.001, min_value=0, max_value=1)\n",
    "time_start = time.time()\n",
    "imputed_values = imputer.fit_transform(mice_X)\n",
    "time_stop = time.time()\n",
    "print(f\"Exec time: {time_stop-time_start}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ab4a29334ff3529"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_mice = pd.DataFrame(imputed_values)\n",
    "data_mice['ViolentCrimesPerPop'] = mice_y\n",
    "data_mice.columns = [col for col in headers if col not in ['state', 'county', 'community', 'communityname', 'fold', ]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16cb6e019ccbc1d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_mice.to_csv(\"data_mice.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9675cae8a3d8dcff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mice_X = data_mice.iloc[:,:-1]\n",
    "mice_y = data_mice.iloc[:,-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72cef23da1b8f509"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "35cb0852e6963ef2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TOP 30 MICE FEATURES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90c56aaa52d01dcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_matrix = data_mice.corr().abs()\n",
    "target_correlation = correlation_matrix['ViolentCrimesPerPop']\n",
    "target_correlation = target_correlation.drop(labels=['ViolentCrimesPerPop'])\n",
    "sorted_features = target_correlation.sort_values(ascending=False)\n",
    "top_30_mice_cols = sorted_features.head(30).index.tolist()\n",
    "print(\"Top 30 features with highest correlation to target:\", top_30_mice_cols)\n",
    "top_30_mice_X = mice_X[top_30_mice_cols]\n",
    "top_30_mice_X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "658e7893c75e8a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_30_mice_X.to_csv(\"top_30_mice_X.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3d75aeb840a454f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA IMPUTED BY AUTOENCODER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "286f919b36c9e68d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.regularizers import l1_l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.src.layers import Dropout\n",
    "from copy import copy\n",
    "\n",
    "auto = copy(data.astype(np.float32))\n",
    "auto_X = auto.iloc[:,:-1]\n",
    "auto_y = auto.iloc[:,-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2f3f258a85a6e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_X_array: np.ndarray = auto_X.astype(np.float32).to_numpy()\n",
    "\n",
    "mask = pd.isna(auto_X).to_numpy()\n",
    "\n",
    "auto_X_filled = auto_X.fillna(0)\n",
    "\n",
    "auto_X_filled_array: np.ndarray = auto_X_filled.to_numpy()\n",
    "\n",
    "X_train, X_val = train_test_split(auto_X_filled_array, test_size=0.2, random_state=42)\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 50\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(input_layer)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=1000,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, X_val),\n",
    "                callbacks=[early_stopping])\n",
    "\n",
    "predicted = autoencoder.predict(auto_X_filled_array)\n",
    "is_missing = pd.isna(auto_X)\n",
    "\n",
    "auto_X_imputed = np.where(is_missing, predicted, auto_X_filled_array)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23f80875b7f89731"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_auto = pd.DataFrame(auto_X_imputed)\n",
    "data_auto.columns = [col for col in headers if col not in ['state', 'county', 'community', 'communityname', 'fold', 'ViolentCrimesPerPop']]\n",
    "data_auto['ViolentCrimesPerPop'] = auto_y\n",
    "data_auto"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb28cc4ca1f41c41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_auto.to_csv(\"data_auto.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73b43bdd3cba8be4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_X = data_auto.iloc[:,:-1]\n",
    "auto_y = data_auto.iloc[:,-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef9f094904b66fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TOP 30 AUTOENCODER FEATURES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca6ce99e9f17790b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_matrix = data_auto.corr().abs()\n",
    "target_correlation = correlation_matrix['ViolentCrimesPerPop']\n",
    "target_correlation = target_correlation.drop(labels=['ViolentCrimesPerPop'])\n",
    "sorted_features = target_correlation.sort_values(ascending=False)\n",
    "top_30_auto_cols = sorted_features.head(30).index.tolist()\n",
    "\n",
    "print(\"Top 30 features with highest correlation to target:\", top_30_auto_cols)\n",
    "top_30_auto_X = auto_X[top_30_auto_cols]\n",
    "top_30_auto_X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "751b95807910f68f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_30_auto_X.to_csv(\"top_30_auto_X.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "149d284b8b408058"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA for MICE  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e70fe479ed6e37cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "mice_X_scaled = sc.fit_transform(mice_X)\n",
    "pca = PCA(n_components= 33)\n",
    "pca_mice_X = pca.fit_transform(mice_X_scaled)\n",
    "pca_mice_X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9fd49be8302985d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(pca_mice_X).to_csv(\"X_pca_mice.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88a57039dbd25e7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA for AUTOENCODER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74846677bcc6c852"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "auto_X_scaled = sc.fit_transform(auto_X)\n",
    "pca = PCA(n_components= 33)\n",
    "pca_auto_X = pca.fit_transform(auto_X_scaled)\n",
    "pca_auto_X"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c0c39426d606ef0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(pca_auto_X).to_csv(\"X_pca_auto.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6c9900fbd0dde33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# READING IN ALL DATA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a32b58853d544219"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "data_mice = pd.read_csv(\"data_mice.csv\")\n",
    "mice_X = data_mice.iloc[:,:-1]\n",
    "mice_y = data_mice.iloc[:,-1]\n",
    "\n",
    "data_auto = pd.read_csv(\"data_auto.csv\")\n",
    "auto_X = data_auto.iloc[:,:-1]\n",
    "auto_y = data_auto.iloc[:,-1]\n",
    "\n",
    "top_30_mice_X = pd.read_csv(\"top_30_mice_X.csv\")\n",
    "\n",
    "top_30_auto_X = pd.read_csv(\"top_30_auto_X.csv\")\n",
    "\n",
    "pca_mice_X = pd.read_csv(\"X_pca_mice.csv\")\n",
    "\n",
    "pca_auto_X = pd.read_csv(\"X_pca_auto.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "761035cd4ff3596e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA ANALYSIS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a4fc724eb783c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corrmat = mice_X.corr()\n",
    "fig = plt.figure(figsize = (16, 12))\n",
    "\n",
    "sns.heatmap(corrmat, vmax = 0.8)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3471130ac276a17f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca = pca.fit(mice_X)\n",
    "\n",
    "cumulative_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_explained_variance, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Different Principal Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92514131b270633c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BEST HYPERPARAM SEARCH"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3dafd6ae2defdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "hyper_params = {}\n",
    "\n",
    "hyper_params[LinearRegression] = {\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# RANSACRegressor\n",
    "hyper_params[RANSACRegressor] = {\n",
    "    'min_samples': hp.choice('min_samples', [0.1, 0.5]),\n",
    "    'max_trials': hp.choice('max_trials', [50, 100, 200]),\n",
    "    'loss': hp.choice('loss', ['squared_error', 'absolute_error']),\n",
    "    'residual_threshold': hp.choice('residual_threshold', [5, 10, 15])\n",
    "}\n",
    "\n",
    "# Lasso\n",
    "hyper_params[Lasso] = {\n",
    "    'alpha': hp.choice('alpha', [0.001, 0.01, 0.1, 1, 10]),\n",
    "    'max_iter': hp.choice('max_iter', [1000, 5000, 10000]),\n",
    "    'tol': hp.choice('tol', [0.0001, 0.001])\n",
    "}\n",
    "\n",
    "# Ridge\n",
    "hyper_params[Ridge] = {\n",
    "    'alpha': hp.choice('alpha', [0.001, 0.01, 0.1, 1, 10]),\n",
    "    'solver': hp.choice('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
    "}\n",
    "\n",
    "# ElasticNetCV\n",
    "hyper_params[ElasticNetCV] = {\n",
    "    'l1_ratio': hp.choice('l1_ratio', [0.2, 0.5, 0.8]),\n",
    "    'max_iter': hp.choice('max_iter', [1000, 5000])\n",
    "}\n",
    "\n",
    "# SVR\n",
    "# hyper_params[SVR] = {\n",
    "#     'C': hp.choice('C', [0.1, 1, 10, 100]),\n",
    "#     'gamma': hp.choice('gamma', ['scale', 'auto']),\n",
    "#     'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "#     'epsilon': hp.choice('epsilon', [0.01, 0.1, 0.2])\n",
    "# }\n",
    "\n",
    "# RandomForestRegressor\n",
    "hyper_params[RandomForestRegressor] = {\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 200, 500]),\n",
    "    'max_features': hp.choice('max_features', ['log2', 'sqrt']),\n",
    "    'max_depth': hp.choice('max_depth', [None, 10, 20, 30]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4])\n",
    "}\n",
    "\n",
    "# XGBRegressor\n",
    "hyper_params[XGBRegressor] = {\n",
    "    'learning_rate': hp.choice('learning_rate', [0.01, 0.1, 0.2]),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 200, 300]),\n",
    "    'max_depth': hp.choice('max_depth', [3, 6, 10]),\n",
    "    'min_child_weight': hp.choice('min_child_weight', [1, 3, 5]),\n",
    "    'subsample': hp.choice('subsample', [0.7, 0.8, 0.9]),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', [0.7, 0.8, 0.9])\n",
    "}\n",
    "\n",
    "hyper_params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9dcfd06f5415b72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results:pd.DataFrame = pd.DataFrame(columns = [\"model\", \"mice_X\", \"auto_X\", \"top_30_mice_X\", \"top_30_auto_X\", \"pca_mice_X\", \"pca_auto_X\"])\n",
    "\n",
    "for model in hyper_params.keys():\n",
    "    results.loc[len(results)] = [model.__name__, \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", ]\n",
    "results = results.astype(object)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f905256acf05108"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(results, \"results.joblib\")\n",
    "results.to_csv(\"results.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9c95b81d8f0120"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "results: pd.DataFrame = load(\"results.joblib\")\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "294ad8f9e25d37e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def change_value_at(data: pd.DataFrame, col_name_of_row, row_name, col_to_change, new_value):\n",
    "    data.at[data[data[col_name_of_row] == row_name].index[0], col_to_change] = new_value\n",
    "\n",
    "def get_value_at(data: pd.DataFrame, col_name_of_row, row_name, col_to_change):\n",
    "    return data.at[data[data[col_name_of_row] == row_name].index[0], col_to_change]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36460165bc756328"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_datas = {\n",
    "    \"mice_X\": mice_X,\n",
    "    \"auto_X\": auto_X,\n",
    "    \"top_30_mice_X\": top_30_mice_X,\n",
    "    \"top_30_auto_X\": top_30_auto_X,\n",
    "    \"pca_mice_X\": pca_mice_X,\n",
    "    \"pca_auto_X\": pca_auto_X\n",
    "}\n",
    "\n",
    "for v in X_datas.values():\n",
    "    print(v.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94ea9533dc461c1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for data_name, X_data in X_datas.items():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    for estimator, space in hyper_params.items():\n",
    "        estimator_name = estimator.__name__\n",
    "        print(data_name)\n",
    "        print(estimator_name)\n",
    "\n",
    "        def objective(params: dict):\n",
    "            global results\n",
    "            if \".\" not in params.keys():\n",
    "                model = estimator(**params)\n",
    "            else:\n",
    "                model = estimator()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            if str(get_value_at(results, \"model\", estimator_name, data_name)) == \"nan\":\n",
    "                print(\"Params:\")\n",
    "                print(params)\n",
    "                print(f\"MAE:  {mae}\")\n",
    "                print(f\"MSE: {mse}\")\n",
    "                print(f\"R2:  {r2}\")\n",
    "                info = {\n",
    "                    \"model\": model,\n",
    "                    \"params\": params,\n",
    "                    \"mse\": mse,\n",
    "                    \"mae\": mae,\n",
    "                    \"r2\": r2,\n",
    "                    \"y_pred\": y_pred,\n",
    "                }\n",
    "                change_value_at(results, \"model\", estimator_name, data_name, info)\n",
    "                dump(results, 'results.joblib')\n",
    "                results.to_csv(\"results.csv\", index=False)\n",
    "            else:\n",
    "                if get_value_at(results, \"model\", estimator_name, data_name)[\"mse\"] > mse:\n",
    "                    print(\"Params:\")\n",
    "                    print(params)\n",
    "                    print(f\"MAE:  {mae}\")\n",
    "                    print(f\"MSE: {mse}\")\n",
    "                    print(f\"R2:  {r2}\")\n",
    "                    info = {\n",
    "                        \"model\": model,\n",
    "                        \"params\": params,\n",
    "                        \"mse\": mse,\n",
    "                        \"mae\": mae,\n",
    "                        \"r2\": r2,\n",
    "                        \"y_pred\": y_pred,\n",
    "                    }\n",
    "                    change_value_at(results, \"model\", estimator_name, data_name, info)\n",
    "                    print(\"NEW_BEST!\")\n",
    "                    print(data_name)\n",
    "                    print(estimator_name)\n",
    "                    print(\"Params:\")\n",
    "                    print(params)\n",
    "                    print(f\"MAE: {mae}\")\n",
    "                    print(f\"MSE: {mse}\")\n",
    "                    print(f\"R2: {r2}\")\n",
    "                    dump(results, 'results.joblib')\n",
    "                    results.to_csv(\"results.csv\", index=False)\n",
    "            return mse\n",
    "\n",
    "        if len(space) == 0:\n",
    "            space = {\n",
    "                \".\": \".\"\n",
    "            }\n",
    "\n",
    "        max_evals = 500\n",
    "\n",
    "        max_evals_exceptions = {\n",
    "            \"SVR\" : 2,\n",
    "            \"LinearRegression\": 1,\n",
    "        }\n",
    "\n",
    "        if estimator_name in max_evals_exceptions.keys():\n",
    "            max_evals = max_evals_exceptions[estimator_name]\n",
    "\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=max_evals,\n",
    "                    verbose=True)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ea1bb120aebfbd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dump(results, 'results.joblib')\n",
    "results.to_csv(\"results.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29d9fa32bdbc10bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_metrics = pd.DataFrame(results.apply(lambda x: x.apply(lambda y: 'r2:'+str(y.get('r2'))+\" mse:\"+str(y.get('mse')) if isinstance(y, dict) else y)))\n",
    "results_metrics.to_csv(\"results_metrics.csv\", index=False)\n",
    "results_metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4f2bae6c05243"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_params = pd.DataFrame(results.apply(lambda x: x.apply(lambda y: y.get('params') if isinstance(y, dict) else y)))\n",
    "results_params.to_csv(\"results_params.csv\", index=False)\n",
    "results_params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "483fa51cccc7146"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_r2 = pd.DataFrame(results.apply(lambda x: x.apply(lambda y: float(y.get('r2')) if isinstance(y, dict) else y)))\n",
    "results_r2.to_csv(\"results_r2.csv\", index=False)\n",
    "results_r2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc13d7f0aa1e0bda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_best_r2 = pd.DataFrame(results_r2[[col for col in results.columns if col != \"model\"]].max())\n",
    "results_best_r2.to_csv(\"results_best_r2.csv\", index=False)\n",
    "results_best_r2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98aa2fab3c6a0ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in results_params[[c for c in results_params.columns if c != \"model\"]].columns:\n",
    "    print(col, \":\\n\")\n",
    "    for model in results_params[\"model\"]:\n",
    "        print(model)\n",
    "        print(get_value_at(results_params, \"model\", model, col))\n",
    "        print(\"R2:\",get_value_at(results, \"model\", model, col)[\"r2\"])\n",
    "        print()\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "698e4d30d180efe8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LIGHTGBM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0044c921a585183"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "estimator_name = lgb.__name__\n",
    "\n",
    "#results.loc[len(results)] = [estimator_name, \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", ]\n",
    "\n",
    "lightgbm_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    'num_leaves': hp.choice('num_leaves', [20, 30, 40, 50]),\n",
    "    'max_depth': hp.choice('max_depth', [5, 10, 15, 20]),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 200, 300]),\n",
    "    'verbose_eval' : -1,\n",
    "    'verbose' : -1\n",
    "}\n",
    "\n",
    "\n",
    "for data_name, X_data in X_datas.items():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y, test_size=0.25, random_state=42)\n",
    "    print(data_name)\n",
    "    print(estimator_name)\n",
    "\n",
    "    def objective(params: dict):\n",
    "        global results\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        num_round = 10000\n",
    "        model = lgb.train(params, train_data, num_round)\n",
    "        y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        if str(get_value_at(results, \"model\", estimator_name, data_name)) == \"nan\":\n",
    "            print(\"Params:\")\n",
    "            print(params)\n",
    "            print(f\"MAE:  {mae}\")\n",
    "            print(f\"MSE: {mse}\")\n",
    "            print(f\"R2:  {r2}\")\n",
    "            info = {\n",
    "                \"model\": model,\n",
    "                \"params\": params,\n",
    "                \"mse\": mse,\n",
    "                \"mae\": mae,\n",
    "                \"r2\": r2,\n",
    "                \"y_pred\": y_pred,\n",
    "            }\n",
    "            change_value_at(results, \"model\", estimator_name, data_name, info)\n",
    "            dump(results, 'results.joblib')\n",
    "            results.to_csv(\"results.csv\", index=False)\n",
    "        else:\n",
    "            if get_value_at(results, \"model\", estimator_name, data_name)[\"mse\"] > mse:\n",
    "                print(\"Params:\")\n",
    "                print(params)\n",
    "                print(f\"MAE:  {mae}\")\n",
    "                print(f\"MSE: {mse}\")\n",
    "                print(f\"R2:  {r2}\")\n",
    "                info = {\n",
    "                    \"model\": model,\n",
    "                    \"params\": params,\n",
    "                    \"mse\": mse,\n",
    "                    \"mae\": mae,\n",
    "                    \"r2\": r2,\n",
    "                    \"y_pred\": y_pred,\n",
    "                }\n",
    "                change_value_at(results, \"model\", estimator_name, data_name, info)\n",
    "                print(\"NEW_BEST!\")\n",
    "                print(data_name)\n",
    "                print(estimator_name)\n",
    "                print(\"Params:\")\n",
    "                print(params)\n",
    "                print(f\"MAE: {mae}\")\n",
    "                print(f\"MSE: {mse}\")\n",
    "                print(f\"R2: {r2}\")\n",
    "                dump(results, 'results.joblib')\n",
    "                results.to_csv(\"results.csv\", index=False)\n",
    "        return mse\n",
    "\n",
    "    max_evals = 500\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=lightgbm_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                verbose=True)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7be5cb8bb396b271"
  },
  {
   "cell_type": "markdown",
   "source": [
    "mice_X :\n",
    "MSE: 0.017265604090334365\n",
    "R^2: 0.6449182172952841\n",
    "auto_X :\n",
    "MSE: 0.017607750523569988\n",
    "R^2: 0.6378816858873053\n",
    "top_30_mice_X :\n",
    "MSE: 0.018909421471191505\n",
    "R^2: 0.6111117195334994\n",
    "top_30_auto_X :\n",
    "MSE: 0.018264735392587623\n",
    "R^2: 0.6243702351856526\n",
    "pca_mice_X :\n",
    "MSE: 0.01872665901810104\n",
    "R^2: 0.6148703842935224\n",
    "pca_auto_X :\n",
    "MSE: 0.01872039032458797\n",
    "R^2: 0.6149993052890581\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da92e7a065b8313e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CATBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "106798faef16b972"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "estimator_name = CatBoostRegressor.__name__\n",
    "\n",
    "#results.loc[len(results)] = [estimator_name, \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", \"nan\", ]\n",
    "\n",
    "import hyperopt.hp as hp\n",
    "\n",
    "catboost_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    'depth': hp.choice('depth', [4, 6, 8, 10]),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1, 10),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0, 1),\n",
    "    'border_count': hp.choice('border_count', [32, 64, 128, 256]),\n",
    "    'iterations': hp.choice('iterations', [500, 1000, 1500]),\n",
    "    'random_strength': hp.uniform('random_strength', 0, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "    'min_child_samples': hp.choice('min_child_samples', [1, 5, 10, 20]),\n",
    "    'custom_metric': ['RMSE'],\n",
    "    'eval_metric': 'RMSE',\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "for data_name, X_data in X_datas.items():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y, test_size=0.25, random_state=42)\n",
    "    print(data_name)\n",
    "    print(estimator_name)\n",
    "\n",
    "    def objective(params: dict):\n",
    "        global results\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        if str(get_value_at(results, \"model\", estimator_name, data_name)) == \"nan\":\n",
    "            print(\"Params:\")\n",
    "            print(params)\n",
    "            print(f\"MAE:  {mae}\")\n",
    "            print(f\"MSE: {mse}\")\n",
    "            print(f\"R2:  {r2}\")\n",
    "            info = {\n",
    "                \"model\": model,\n",
    "                \"params\": params,\n",
    "                \"mse\": mse,\n",
    "                \"mae\": mae,\n",
    "                \"r2\": r2,\n",
    "                \"y_pred\": y_pred,\n",
    "            }\n",
    "            change_value_at(results, \"model\", estimator_name, data_name, info)\n",
    "            dump(results, 'results.joblib')\n",
    "            results.to_csv(\"results.csv\", index=False)\n",
    "        else:\n",
    "            if get_value_at(results, \"model\", estimator_name, data_name)[\"mse\"] > mse:\n",
    "                print(\"Params:\")\n",
    "                print(params)\n",
    "                print(f\"MAE:  {mae}\")\n",
    "                print(f\"MSE: {mse}\")\n",
    "                print(f\"R2:  {r2}\")\n",
    "                info = {\n",
    "                    \"model\": model,\n",
    "                    \"params\": params,\n",
    "                    \"mse\": mse,\n",
    "                    \"mae\": mae,\n",
    "                    \"r2\": r2,\n",
    "                    \"y_pred\": y_pred,\n",
    "                }\n",
    "                change_value_at(results, \"model\", estimator_name, data_name, info)\n",
    "                print(\"NEW_BEST!\")\n",
    "                print(data_name)\n",
    "                print(estimator_name)\n",
    "                print(\"Params:\")\n",
    "                print(params)\n",
    "                print(f\"MAE: {mae}\")\n",
    "                print(f\"MSE: {mse}\")\n",
    "                print(f\"R2: {r2}\")\n",
    "                dump(results, 'results.joblib')\n",
    "                results.to_csv(\"results.csv\", index=False)\n",
    "        return mse\n",
    "\n",
    "    max_evals = 500\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=catboost_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                verbose=True)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1aa6b4b4737a4ba5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STANDARD NEURAL NETWORK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "864c7614af84202a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.layers import Dropout\n",
    "from keras.src.regularizers import l2\n",
    "from keras.src.layers import LeakyReLU\n",
    "from keras.src.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import tensorflow as tf\n",
    "\n",
    "global model\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=30, max_value=30, step=1), activation='relu', input_shape=(mice_X.shape[1],)))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('units1', min_value=55, max_value=65, step=1), activation=LeakyReLU(alpha=hp.Float('alpha1', min_value=0.01, max_value=0.05, step=1))))\n",
    "    model.add(Dense(units=hp.Int('units2', min_value=40, max_value=50, step=1), activation=LeakyReLU(alpha=hp.Float('alpha2', min_value=0.01, max_value=0.05, step=1))))\n",
    "    model.add(Dense(units=hp.Int('units3', min_value=31, max_value=41, step=1), activation=LeakyReLU(alpha=hp.Float('alpha3', min_value=0.01, max_value=0.05, step=1))))\n",
    "    model.add(Dense(units=hp.Int('units3', min_value=56, max_value=66, step=1), activation=LeakyReLU(alpha=hp.Float('alpha4', min_value=0.01, max_value=0.05, step=1))))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    # from this but 0.805 [30 55 51 26]\n",
    "    # from mlp reg [58, 45, 36, 61]\n",
    "    lr_scheduler= ExponentialDecay(\n",
    "        0.00001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9,\n",
    "    )\n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='nn_model_v7'\n",
    ")\n",
    "\n",
    "tuner.search(mice_X, mice_y, epochs=300, validation_split=0.25, verbose=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc97a378cb7fc2eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h = tuner.get_best_hyperparameters()[0]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"The best hyperparameters are:\")\n",
    "print(f\" - Units in the first dense layer: {h.get('units')}\")\n",
    "print(f\" - Units in the second dense layer: {h.get('units1')}\")\n",
    "print(f\" - Units in the third dense layer: {h.get('units2')}\")\n",
    "print(f\" - Units in the fourth dense layer: {h.get('units3')}\")\n",
    "print(f\" - Learning rate for the optimizer: {h.get('alpha1')}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83e857b9cea12ce9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"R^2: {r2}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20160daa189c7e99"
  },
  {
   "cell_type": "markdown",
   "source": [
    " # MLP REGRESSOR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff4058aef519daa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "estimators_params = {}\n",
    "\n",
    "\n",
    "estimators_params[MLPRegressor] ={\n",
    "    'layer_number': hp.choice('layer_number', range(4,5)),\n",
    "    'nn1' : hp.choice(\"nn1\", range(53,63,1)),\n",
    "    'nn2' : hp.choice(\"nn2\", range(40,50,1)),\n",
    "    'nn3' : hp.choice(\"nn3\", range(31,41,1)),\n",
    "    'nn4' : hp.choice(\"nn4\", range(56,67,1)),\n",
    "    'activation': hp.choice('activation', ['relu', 'tanh']),\n",
    "    'solver': 'lbfgs',\n",
    "    'alpha': hp.uniform('alpha', 0.17, 0.22),\n",
    "    'max_iter': hp.choice('max_iter', range(1200, 1300, 10)),\n",
    "    'tol': hp.uniform('tol', 1e-6, 1e-3),\n",
    "    'shuffle': hp.choice('shuffle', [True, False]),\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.25,\n",
    "}\n",
    "\n",
    "\n",
    "for data_name, X_data in X_datas.items():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y, test_size=0.25, random_state=42)\n",
    "    print(data_name)\n",
    "    print(estimator_name)\n",
    "\n",
    "    try:\n",
    "        best_combo\n",
    "    except NameError:\n",
    "        best_combo = None\n",
    "\n",
    "    best_estimators = {}\n",
    "    for estimator, space in estimators_params.items():\n",
    "        print(estimator)\n",
    "\n",
    "        def objective(params: dict):\n",
    "\n",
    "            global best_combo\n",
    "\n",
    "            params[\"hidden_layer_sizes\"] = [params.pop(\"nn\"+str(i)) for i in range(1,params.pop(\"layer_number\")+1)]\n",
    "            for i in range(6):\n",
    "                if \"nn\"+str(i) in params.keys():\n",
    "                    params.pop(\"nn\"+str(i))\n",
    "            model = estimator(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            print(f\"MSE: {mse}\")\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            print(f\"MAE:  {mae}\")\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            print(f\"R2:  {r2}\")\n",
    "            if best_combo is None:\n",
    "                best_combo = {\n",
    "                    \"model\": model,\n",
    "                    \"mse\" : mse,\n",
    "                    \"mae\" : mae,\n",
    "                    \"r2\" : r2,\n",
    "                    \"y_pred\": y_pred,\n",
    "                }\n",
    "            else:\n",
    "                if best_combo[\"mse\"] > mse:\n",
    "                    best_combo = {\n",
    "                        \"model\": model,\n",
    "                        \"mse\" : mse,\n",
    "                        \"mae\" : mae,\n",
    "                        \"r2\" : r2,\n",
    "                        \"y_pred\": y_pred,\n",
    "                    }\n",
    "                    print(\"NEW_BEST_COMBO!\")\n",
    "                    print(f\"MSE: {mse}\")\n",
    "                    print(f\"MAE: {mae}\")\n",
    "                    print(f\"R2: {r2}\")\n",
    "                    dump(best_combo, 'best_combo_temp2.joblib')\n",
    "            return mse\n",
    "\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=10000,\n",
    "                    verbose=True)\n",
    "\n",
    "        print(\"BEST:\")\n",
    "        best_params = space_eval(space, best)\n",
    "        best_estimator = estimator(**best_params)\n",
    "        best_estimator.fit(X_train, y_train)\n",
    "        y_pred_est = best_estimator.predict(X_val)\n",
    "        mae_est = mean_absolute_error(y_val, y_pred_est)\n",
    "        mse_est = mean_squared_error(y_val, y_pred_est)\n",
    "        r2_est = r2_score(y_val, y_pred_est)\n",
    "        print(f\"MAE: {mae_est}\")\n",
    "        print(f\"MSE: {mse_est}\")\n",
    "        print(f\"R2: {r2_est}\")\n",
    "        print(\"BEST:\",best_params)\n",
    "        best_estimators[mse_est] = (best_estimator, best_params)\n",
    "\n",
    "best_mse = min(best_estimators.keys())\n",
    "best_regressor= (best_estimators[best_mse],  best_mse)\n",
    "print(best_combo)\n",
    "dump(best_combo, 'best_combo_new3.joblib')\n",
    "print(best_regressor)\n",
    "dump(best_regressor, 'best_regressor_new3.joblib')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "634a78e9c496661a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_combo[\"model\"].get_params())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99c55d5f1903203e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_regressor)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c9c04e01d89a494"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def measure(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y, preds),\n",
    "        \"MSE\": mean_squared_error(y, preds),\n",
    "        \"R2\": r2_score(y, preds),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2dae737dd1e928b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "print(load(\"best_combo_temp_005400.joblib\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43c3290161ac925a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "measure(load(\"best_combo_temp_005400.joblib\")[\"model\"], X_val, y_val)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc03f07eee1e1eb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(load('mlp_regressor_model.joblib'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cd36c816e420170"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
